{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KRR on ICTUS dataset after projection onto NN centers\n",
    "\n",
    "Simple neural networks achieve good performance on this dataset. We take a set of 7 centers from a sigmoid NN and project the whole data on these centers (effectively the centers are a dicionary learned using label supervision).\n",
    "\n",
    "Then applying KRR on the projected data achieves similar results of the neural net.\n",
    "\n",
    "We also run the same experiment taking as centers, the points closest to the NN centers in the dataset. This nearest neighbor analysis is done in the `DataDistance` notebook.\n",
    "The result is that nearest-neighbor centers **do not behave the same as the neural-net centers**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../PyFalkon/src\")\n",
    "import time\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "\n",
    "from falkon import Falkon \n",
    "from nystrom import select_uniform_centers\n",
    "from kernels import *\n",
    "from utils import load_mat_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"../run_all.mat\"\n",
    "X, Y = load_mat_data(fname)\n",
    "Y[Y == 0.0] = -1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "scaler = preprocessing.StandardScaler(copy=False, with_mean=True, with_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Trained NN Weights\n",
    "\n",
    "We train a simple neural net as specified below\n",
    "```python\n",
    " nn.Sequential(\n",
    "    nn.Linear(992, 7),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(7, 1))\n",
    "```\n",
    "which achieves 3,08% test error.\n",
    "\n",
    "Other parameters:\n",
    " - batch size: 128\n",
    " - loss: L2\n",
    " - lr: 2e-3\n",
    " - opt: Adam (no weight decay)\n",
    "see the file `neural_test.py` for more details.\n",
    "\n",
    "We extract the first layer weights of the trained NN (called `W0` below, of shape $7\\times992$) and apply them to the original data as a dimensionality-reduction / feature extraction step.\n",
    "\n",
    "We then train Falkon on the resulting data.\n",
    "The results are heavily dependent on sigma, but with $\\sigma = 1$ we find that we achieve results on par with the neural net (i.e. 3.42% test error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 992)\n",
      "(1, 7)\n"
     ]
    }
   ],
   "source": [
    "weights = scipy.io.loadmat(\"nn_weights7sigmoid.mat\")\n",
    "W0 = weights[\"W0\"]\n",
    "W1 = weights[\"W1\"]\n",
    "print(W0.shape)\n",
    "print(W1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 5000\n",
    "sigma = 1\n",
    "l = 1e-15\n",
    "kernel = GaussianKernel(sigma)\n",
    "np.random.seed(34)\n",
    "\n",
    "F = Falkon(kernel, l, M=M, maxiter=20, max_ram=1*2**30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../PyFalkon/src/falkon.py:110: UserWarning: Conjugate gradient descent did not converge after 20 iterations!\n",
      "  warnings.warn(f\"Conjugate gradient descent did not converge after {info} iterations!\")\n"
     ]
    }
   ],
   "source": [
    "train_err, test_err = [], []\n",
    "for train, test in kf.split(X):\n",
    "    X_train, X_test, Y_train, Y_test = X[train], X[test], Y[train], Y[test]\n",
    "    scaler.fit(X_train, X_test)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train_nn = np.matmul(X_train, W0.T)\n",
    "    X_test_nn = np.matmul(X_test, W0.T)\n",
    "    \n",
    "    F.fit(X_train_nn, Y_train)\n",
    "    train_pred = F.predict(X_train_nn)\n",
    "    test_pred = F.predict(X_test_nn)\n",
    "    train_err.append(np.mean(np.sign(train_pred) != Y_train))\n",
    "    test_err.append(np.mean(np.sign(test_pred) != Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 2.56% - Test error: 3.32%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error: %.2f%% - Test error: %.2f%%\" % \n",
    "      (np.mean(train_err)*100, np.mean(test_err)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Replace NN centers by their nearest neighbors\n",
    "\n",
    "The replacement centers are data-points identified in the `DataDistance` notebook:\n",
    "`9398, 12645, 13891, 9888, 29274, 6965, 20633`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "Xscaled = scale(X, axis=0, with_mean=True, with_std=True)\n",
    "center_idx = [9398, 12645, 13891, 9888, 29274, 6965, 20633]\n",
    "Xcenters = Xscaled[center_idx]\n",
    "Xrest = np.delete(X, np.array(center_idx), axis=0)\n",
    "Yrest = np.delete(Y, np.array(center_idx), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 5000\n",
    "sigma = 25\n",
    "l = 1e-15\n",
    "kernel = GaussianKernel(sigma)\n",
    "np.random.seed(34)\n",
    "\n",
    "F = Falkon(kernel, l, M=M, maxiter=30, max_ram=1*2**30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "train_err, test_err = [], []\n",
    "for train, test in kf.split(Xrest):\n",
    "    X_train, X_test, Y_train, Y_test = Xrest[train], Xrest[test], Yrest[train], Yrest[test]\n",
    "    scaler.fit(X_train, X_test)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train_proj = np.matmul(X_train, Xcenters.T)\n",
    "    X_test_proj = np.matmul(X_test, Xcenters.T)\n",
    "    \n",
    "    F.fit(X_train_proj, Y_train)\n",
    "    train_pred = F.predict(X_train_proj)\n",
    "    test_pred = F.predict(X_test_proj)\n",
    "    train_err.append(np.mean(np.sign(train_pred) != Y_train))\n",
    "    test_err.append(np.mean(np.sign(test_pred) != Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 26.26% - Test error: 38.44%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train error: %.2f%% - Test error: %.2f%%\" % \n",
    "      (np.mean(train_err)*100, np.mean(test_err)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
